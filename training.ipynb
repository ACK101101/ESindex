{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IndexDataset import IndexDataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# dataset_name = \"data/imdb/imdb_top_1000.csv\"\n",
    "# column_name = \"Overview\"\n",
    "dataset_name = \"data/lego/inventory_parts.csv\"\n",
    "column_name = \"part_num\"\n",
    "batch_size = 128\n",
    "\n",
    "df = pd.read_csv(dataset_name)\n",
    "dataset = IndexDataset(df, column_name)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class LitIndexer(L.LightningModule):\n",
    "    def __init__(self, mapper, indexer):\n",
    "        super().__init__()\n",
    "        self.mapper = mapper\n",
    "        self.indexer = indexer\n",
    "        self.min_loss = float(\"inf\")\n",
    "        self.epoch_losses = []\n",
    "        \n",
    "    def loss(self, pred_idxs, real_idxs):\n",
    "        return F.mse_loss(pred_idxs, real_idxs)\n",
    "    \n",
    "    def percent_narrowed(self, loss):\n",
    "        return math.sqrt(loss) / len(self.mapper.data)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        strs, idxs = batch\n",
    "        mapped_strs = self.mapper.forward(strs)\n",
    "        pred_idxs = self.indexer(mapped_strs)\n",
    "        loss = self.loss(pred_idxs, idxs.to(torch.float32))\n",
    "        self.min_loss = min(self.min_loss, loss)\n",
    "        # print(self.percent_narrowed(loss))\n",
    "        # print(self.min_loss)\n",
    "        # print(pred_idxs, idxs)\n",
    "        self.epoch_losses.append(loss)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        avg_epoch_loss = sum(self.epoch_losses) / len(self.epoch_losses)\n",
    "        print(f\"Epoch {self.current_epoch}, Average Epoch Loss: {avg_epoch_loss:.4f}, Percent Narrowed: {self.percent_narrowed(avg_epoch_loss):.4f}\")\n",
    "        self.epoch_losses = []\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        strs, idxs = batch\n",
    "        mapped_strs = self.mappers(strs)\n",
    "        pred_idxs = self.indexer(mapped_strs)\n",
    "        loss = self.loss(pred_idxs, idxs)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-2)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type                  | Params\n",
      "--------------------------------------------------\n",
      "0 | indexer | LinearRegressionModel | 2     \n",
      "--------------------------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe90413ff6e489183cc9943183dba86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/5hbdnj_57xv861zqcz43bs6w0000gn/T/ipykernel_8355/2473563307.py:16: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred_idxs, real_idxs)\n",
      "/var/folders/9c/5hbdnj_57xv861zqcz43bs6w0000gn/T/ipykernel_8355/2473563307.py:16: UserWarning: Using a target size (torch.Size([68])) that is different to the input size (torch.Size([68, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred_idxs, real_idxs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Epoch Loss: 33762636.0000, Percent Narrowed: 0.6259\n",
      "Epoch 1, Average Epoch Loss: 15921622.0000, Percent Narrowed: 0.4298\n",
      "Epoch 2, Average Epoch Loss: 12810526.0000, Percent Narrowed: 0.3855\n",
      "Epoch 3, Average Epoch Loss: 12598139.0000, Percent Narrowed: 0.3823\n",
      "Epoch 4, Average Epoch Loss: 12571978.0000, Percent Narrowed: 0.3819\n",
      "Epoch 5, Average Epoch Loss: 12572769.0000, Percent Narrowed: 0.3819\n",
      "Epoch 6, Average Epoch Loss: 12572882.0000, Percent Narrowed: 0.3819\n",
      "Epoch 7, Average Epoch Loss: 12559731.0000, Percent Narrowed: 0.3817\n",
      "Epoch 8, Average Epoch Loss: 12575619.0000, Percent Narrowed: 0.3820\n",
      "Epoch 9, Average Epoch Loss: 12575400.0000, Percent Narrowed: 0.3820\n",
      "Epoch 10, Average Epoch Loss: 12585889.0000, Percent Narrowed: 0.3821\n",
      "Epoch 11, Average Epoch Loss: 12550513.0000, Percent Narrowed: 0.3816\n",
      "Epoch 12, Average Epoch Loss: 12563933.0000, Percent Narrowed: 0.3818\n",
      "Epoch 13, Average Epoch Loss: 12568515.0000, Percent Narrowed: 0.3819\n",
      "Epoch 14, Average Epoch Loss: 12559457.0000, Percent Narrowed: 0.3817\n",
      "Epoch 15, Average Epoch Loss: 12552647.0000, Percent Narrowed: 0.3816\n",
      "Epoch 16, Average Epoch Loss: 12557705.0000, Percent Narrowed: 0.3817\n",
      "Epoch 17, Average Epoch Loss: 12577827.0000, Percent Narrowed: 0.3820\n",
      "Epoch 18, Average Epoch Loss: 12571910.0000, Percent Narrowed: 0.3819\n",
      "Epoch 19, Average Epoch Loss: 12559481.0000, Percent Narrowed: 0.3817\n",
      "Epoch 20, Average Epoch Loss: 12555838.0000, Percent Narrowed: 0.3817\n",
      "Epoch 21, Average Epoch Loss: 12533139.0000, Percent Narrowed: 0.3813\n",
      "Epoch 22, Average Epoch Loss: 12544750.0000, Percent Narrowed: 0.3815\n",
      "Epoch 23, Average Epoch Loss: 12541302.0000, Percent Narrowed: 0.3814\n",
      "Epoch 24, Average Epoch Loss: 12543628.0000, Percent Narrowed: 0.3815\n",
      "Epoch 25, Average Epoch Loss: 12561922.0000, Percent Narrowed: 0.3818\n",
      "Epoch 26, Average Epoch Loss: 12558707.0000, Percent Narrowed: 0.3817\n",
      "Epoch 27, Average Epoch Loss: 12555439.0000, Percent Narrowed: 0.3817\n",
      "Epoch 28, Average Epoch Loss: 12525479.0000, Percent Narrowed: 0.3812\n",
      "Epoch 29, Average Epoch Loss: 12545775.0000, Percent Narrowed: 0.3815\n",
      "Epoch 30, Average Epoch Loss: 12549907.0000, Percent Narrowed: 0.3816\n",
      "Epoch 31, Average Epoch Loss: 12537915.0000, Percent Narrowed: 0.3814\n",
      "Epoch 32, Average Epoch Loss: 12548673.0000, Percent Narrowed: 0.3816\n",
      "Epoch 33, Average Epoch Loss: 12544486.0000, Percent Narrowed: 0.3815\n",
      "Epoch 34, Average Epoch Loss: 12561931.0000, Percent Narrowed: 0.3818\n",
      "Epoch 35, Average Epoch Loss: 12522074.0000, Percent Narrowed: 0.3812\n",
      "Epoch 36, Average Epoch Loss: 12549763.0000, Percent Narrowed: 0.3816\n",
      "Epoch 37, Average Epoch Loss: 12537905.0000, Percent Narrowed: 0.3814\n",
      "Epoch 38, Average Epoch Loss: 12523674.0000, Percent Narrowed: 0.3812\n",
      "Epoch 39, Average Epoch Loss: 12515243.0000, Percent Narrowed: 0.3811\n"
     ]
    }
   ],
   "source": [
    "from models.BaselineHash import BaselineHash\n",
    "from models.LinearModel import LinearRegressionModel\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import mmh3\n",
    "\n",
    "hash = mmh3.hash    # 32-bits\n",
    "mapper = BaselineHash(dataset, hash)\n",
    "indexer = LinearRegressionModel(1)\n",
    "\n",
    "dataset = mapper.data\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LitIndexer(mapper, indexer)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('lightning_logs/')\n",
    "trainer = L.Trainer(accelerator=\"cpu\", logger=tb_logger)\n",
    "trainer.fit(model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "\n",
      "  | Name    | Type                  | Params\n",
      "--------------------------------------------------\n",
      "0 | mapper  | BaselineEmbed         | 38    \n",
      "1 | indexer | LinearRegressionModel | 16    \n",
      "--------------------------------------------------\n",
      "54        Trainable params\n",
      "0         Non-trainable params\n",
      "54        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e0bde24395471dac3c8d2196f1fadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/5hbdnj_57xv861zqcz43bs6w0000gn/T/ipykernel_8355/2473563307.py:16: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred_idxs, real_idxs)\n",
      "/var/folders/9c/5hbdnj_57xv861zqcz43bs6w0000gn/T/ipykernel_8355/2473563307.py:16: UserWarning: Using a target size (torch.Size([57])) that is different to the input size (torch.Size([57, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred_idxs, real_idxs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Epoch Loss: 71533816.0000, Percent Narrowed: 0.5774\n",
      "Epoch 1, Average Epoch Loss: 71218552.0000, Percent Narrowed: 0.5761\n",
      "Epoch 2, Average Epoch Loss: 70450224.0000, Percent Narrowed: 0.5730\n",
      "Epoch 3, Average Epoch Loss: 68993568.0000, Percent Narrowed: 0.5670\n",
      "Epoch 4, Average Epoch Loss: 66678000.0000, Percent Narrowed: 0.5574\n",
      "Epoch 5, Average Epoch Loss: 63426484.0000, Percent Narrowed: 0.5437\n",
      "Epoch 6, Average Epoch Loss: 59574752.0000, Percent Narrowed: 0.5269\n",
      "Epoch 7, Average Epoch Loss: 55471524.0000, Percent Narrowed: 0.5084\n",
      "Epoch 8, Average Epoch Loss: 51179880.0000, Percent Narrowed: 0.4884\n",
      "Epoch 9, Average Epoch Loss: 46987280.0000, Percent Narrowed: 0.4679\n",
      "Epoch 10, Average Epoch Loss: 42977568.0000, Percent Narrowed: 0.4475\n",
      "Epoch 11, Average Epoch Loss: 39282964.0000, Percent Narrowed: 0.4279\n",
      "Epoch 12, Average Epoch Loss: 36018684.0000, Percent Narrowed: 0.4097\n",
      "Epoch 13, Average Epoch Loss: 33229036.0000, Percent Narrowed: 0.3935\n",
      "Epoch 14, Average Epoch Loss: 30810080.0000, Percent Narrowed: 0.3789\n",
      "Epoch 15, Average Epoch Loss: 28816814.0000, Percent Narrowed: 0.3665\n",
      "Epoch 16, Average Epoch Loss: 27295528.0000, Percent Narrowed: 0.3566\n",
      "Epoch 17, Average Epoch Loss: 26022564.0000, Percent Narrowed: 0.3482\n",
      "Epoch 18, Average Epoch Loss: 25082428.0000, Percent Narrowed: 0.3419\n",
      "Epoch 19, Average Epoch Loss: 24359074.0000, Percent Narrowed: 0.3369\n",
      "Epoch 20, Average Epoch Loss: 23754620.0000, Percent Narrowed: 0.3327\n",
      "Epoch 21, Average Epoch Loss: 23311810.0000, Percent Narrowed: 0.3296\n",
      "Epoch 22, Average Epoch Loss: 22904318.0000, Percent Narrowed: 0.3267\n",
      "Epoch 23, Average Epoch Loss: 22506406.0000, Percent Narrowed: 0.3239\n",
      "Epoch 24, Average Epoch Loss: 22198024.0000, Percent Narrowed: 0.3216\n",
      "Epoch 25, Average Epoch Loss: 21868410.0000, Percent Narrowed: 0.3192\n",
      "Epoch 26, Average Epoch Loss: 21552922.0000, Percent Narrowed: 0.3169\n",
      "Epoch 27, Average Epoch Loss: 21307082.0000, Percent Narrowed: 0.3151\n",
      "Epoch 28, Average Epoch Loss: 21017542.0000, Percent Narrowed: 0.3130\n",
      "Epoch 29, Average Epoch Loss: 20741632.0000, Percent Narrowed: 0.3109\n",
      "Epoch 30, Average Epoch Loss: 20501680.0000, Percent Narrowed: 0.3091\n",
      "Epoch 31, Average Epoch Loss: 20292536.0000, Percent Narrowed: 0.3075\n",
      "Epoch 32, Average Epoch Loss: 20084206.0000, Percent Narrowed: 0.3059\n",
      "Epoch 33, Average Epoch Loss: 19862730.0000, Percent Narrowed: 0.3042\n",
      "Epoch 34, Average Epoch Loss: 19701536.0000, Percent Narrowed: 0.3030\n",
      "Epoch 35, Average Epoch Loss: 19561340.0000, Percent Narrowed: 0.3019\n",
      "Epoch 36, Average Epoch Loss: 19415416.0000, Percent Narrowed: 0.3008\n",
      "Epoch 37, Average Epoch Loss: 19285778.0000, Percent Narrowed: 0.2998\n",
      "Epoch 38, Average Epoch Loss: 19175640.0000, Percent Narrowed: 0.2989\n",
      "Epoch 39, Average Epoch Loss: 19079940.0000, Percent Narrowed: 0.2982\n",
      "Epoch 40, Average Epoch Loss: 18980786.0000, Percent Narrowed: 0.2974\n",
      "Epoch 41, Average Epoch Loss: 18899184.0000, Percent Narrowed: 0.2968\n",
      "Epoch 42, Average Epoch Loss: 18818676.0000, Percent Narrowed: 0.2961\n",
      "Epoch 43, Average Epoch Loss: 18750838.0000, Percent Narrowed: 0.2956\n",
      "Epoch 44, Average Epoch Loss: 18675376.0000, Percent Narrowed: 0.2950\n",
      "Epoch 45, Average Epoch Loss: 18611570.0000, Percent Narrowed: 0.2945\n",
      "Epoch 46, Average Epoch Loss: 18560160.0000, Percent Narrowed: 0.2941\n",
      "Epoch 47, Average Epoch Loss: 18526938.0000, Percent Narrowed: 0.2938\n",
      "Epoch 48, Average Epoch Loss: 18509152.0000, Percent Narrowed: 0.2937\n",
      "Epoch 49, Average Epoch Loss: 18483514.0000, Percent Narrowed: 0.2935\n",
      "Epoch 50, Average Epoch Loss: 18417420.0000, Percent Narrowed: 0.2930\n",
      "Epoch 51, Average Epoch Loss: 18418790.0000, Percent Narrowed: 0.2930\n",
      "Epoch 52, Average Epoch Loss: 18390136.0000, Percent Narrowed: 0.2927\n",
      "Epoch 53, Average Epoch Loss: 18356498.0000, Percent Narrowed: 0.2925\n",
      "Epoch 54, Average Epoch Loss: 18342492.0000, Percent Narrowed: 0.2924\n",
      "Epoch 55, Average Epoch Loss: 18317612.0000, Percent Narrowed: 0.2922\n",
      "Epoch 56, Average Epoch Loss: 18292956.0000, Percent Narrowed: 0.2920\n",
      "Epoch 57, Average Epoch Loss: 18282484.0000, Percent Narrowed: 0.2919\n",
      "Epoch 58, Average Epoch Loss: 18281410.0000, Percent Narrowed: 0.2919\n",
      "Epoch 59, Average Epoch Loss: 18273582.0000, Percent Narrowed: 0.2918\n",
      "Epoch 60, Average Epoch Loss: 18245490.0000, Percent Narrowed: 0.2916\n",
      "Epoch 61, Average Epoch Loss: 18228080.0000, Percent Narrowed: 0.2914\n",
      "Epoch 62, Average Epoch Loss: 18208664.0000, Percent Narrowed: 0.2913\n",
      "Epoch 63, Average Epoch Loss: 18214938.0000, Percent Narrowed: 0.2913\n",
      "Epoch 64, Average Epoch Loss: 18192952.0000, Percent Narrowed: 0.2912\n",
      "Epoch 65, Average Epoch Loss: 18193918.0000, Percent Narrowed: 0.2912\n",
      "Epoch 66, Average Epoch Loss: 18188990.0000, Percent Narrowed: 0.2911\n",
      "Epoch 67, Average Epoch Loss: 18162140.0000, Percent Narrowed: 0.2909\n",
      "Epoch 68, Average Epoch Loss: 18167664.0000, Percent Narrowed: 0.2910\n",
      "Epoch 69, Average Epoch Loss: 18181304.0000, Percent Narrowed: 0.2911\n",
      "Epoch 70, Average Epoch Loss: 18150206.0000, Percent Narrowed: 0.2908\n",
      "Epoch 71, Average Epoch Loss: 18147312.0000, Percent Narrowed: 0.2908\n",
      "Epoch 72, Average Epoch Loss: 18143798.0000, Percent Narrowed: 0.2908\n",
      "Epoch 73, Average Epoch Loss: 18156428.0000, Percent Narrowed: 0.2909\n",
      "Epoch 74, Average Epoch Loss: 18131512.0000, Percent Narrowed: 0.2907\n",
      "Epoch 75, Average Epoch Loss: 18134126.0000, Percent Narrowed: 0.2907\n",
      "Epoch 76, Average Epoch Loss: 18113036.0000, Percent Narrowed: 0.2905\n",
      "Epoch 77, Average Epoch Loss: 18127100.0000, Percent Narrowed: 0.2906\n",
      "Epoch 78, Average Epoch Loss: 18121024.0000, Percent Narrowed: 0.2906\n",
      "Epoch 79, Average Epoch Loss: 18100396.0000, Percent Narrowed: 0.2904\n",
      "Epoch 80, Average Epoch Loss: 18133118.0000, Percent Narrowed: 0.2907\n",
      "Epoch 81, Average Epoch Loss: 18100142.0000, Percent Narrowed: 0.2904\n",
      "Epoch 82, Average Epoch Loss: 18099256.0000, Percent Narrowed: 0.2904\n",
      "Epoch 83, Average Epoch Loss: 18081492.0000, Percent Narrowed: 0.2903\n",
      "Epoch 84, Average Epoch Loss: 18075458.0000, Percent Narrowed: 0.2902\n",
      "Epoch 85, Average Epoch Loss: 18077600.0000, Percent Narrowed: 0.2902\n",
      "Epoch 86, Average Epoch Loss: 18078456.0000, Percent Narrowed: 0.2903\n",
      "Epoch 87, Average Epoch Loss: 18082430.0000, Percent Narrowed: 0.2903\n",
      "Epoch 88, Average Epoch Loss: 18044806.0000, Percent Narrowed: 0.2900\n",
      "Epoch 89, Average Epoch Loss: 18064812.0000, Percent Narrowed: 0.2901\n",
      "Epoch 90, Average Epoch Loss: 18073814.0000, Percent Narrowed: 0.2902\n",
      "Epoch 91, Average Epoch Loss: 18046306.0000, Percent Narrowed: 0.2900\n",
      "Epoch 92, Average Epoch Loss: 18049598.0000, Percent Narrowed: 0.2900\n",
      "Epoch 93, Average Epoch Loss: 18048480.0000, Percent Narrowed: 0.2900\n",
      "Epoch 94, Average Epoch Loss: 18048096.0000, Percent Narrowed: 0.2900\n",
      "Epoch 95, Average Epoch Loss: 18049424.0000, Percent Narrowed: 0.2900\n",
      "Epoch 96, Average Epoch Loss: 18049288.0000, Percent Narrowed: 0.2900\n",
      "Epoch 97, Average Epoch Loss: 18049246.0000, Percent Narrowed: 0.2900\n",
      "Epoch 98, Average Epoch Loss: 18023944.0000, Percent Narrowed: 0.2898\n",
      "Epoch 99, Average Epoch Loss: 18036388.0000, Percent Narrowed: 0.2899\n",
      "Epoch 100, Average Epoch Loss: 18029364.0000, Percent Narrowed: 0.2899\n",
      "Epoch 101, Average Epoch Loss: 18029202.0000, Percent Narrowed: 0.2899\n",
      "Epoch 102, Average Epoch Loss: 18024618.0000, Percent Narrowed: 0.2898\n",
      "Epoch 103, Average Epoch Loss: 18004938.0000, Percent Narrowed: 0.2897\n",
      "Epoch 104, Average Epoch Loss: 18033222.0000, Percent Narrowed: 0.2899\n",
      "Epoch 105, Average Epoch Loss: 18016006.0000, Percent Narrowed: 0.2897\n",
      "Epoch 106, Average Epoch Loss: 18028096.0000, Percent Narrowed: 0.2898\n",
      "Epoch 107, Average Epoch Loss: 18025244.0000, Percent Narrowed: 0.2898\n",
      "Epoch 108, Average Epoch Loss: 18013664.0000, Percent Narrowed: 0.2897\n",
      "Epoch 109, Average Epoch Loss: 18020232.0000, Percent Narrowed: 0.2898\n",
      "Epoch 110, Average Epoch Loss: 18024234.0000, Percent Narrowed: 0.2898\n",
      "Epoch 111, Average Epoch Loss: 18005064.0000, Percent Narrowed: 0.2897\n",
      "Epoch 112, Average Epoch Loss: 18003390.0000, Percent Narrowed: 0.2896\n",
      "Epoch 113, Average Epoch Loss: 18008056.0000, Percent Narrowed: 0.2897\n",
      "Epoch 114, Average Epoch Loss: 17990998.0000, Percent Narrowed: 0.2895\n",
      "Epoch 115, Average Epoch Loss: 18009740.0000, Percent Narrowed: 0.2897\n",
      "Epoch 116, Average Epoch Loss: 17998900.0000, Percent Narrowed: 0.2896\n",
      "Epoch 117, Average Epoch Loss: 17989306.0000, Percent Narrowed: 0.2895\n",
      "Epoch 118, Average Epoch Loss: 17979212.0000, Percent Narrowed: 0.2895\n",
      "Epoch 119, Average Epoch Loss: 18010956.0000, Percent Narrowed: 0.2897\n",
      "Epoch 120, Average Epoch Loss: 18010786.0000, Percent Narrowed: 0.2897\n",
      "Epoch 121, Average Epoch Loss: 18003542.0000, Percent Narrowed: 0.2896\n",
      "Epoch 122, Average Epoch Loss: 17986088.0000, Percent Narrowed: 0.2895\n",
      "Epoch 123, Average Epoch Loss: 17999864.0000, Percent Narrowed: 0.2896\n",
      "Epoch 124, Average Epoch Loss: 18001286.0000, Percent Narrowed: 0.2896\n",
      "Epoch 125, Average Epoch Loss: 18010910.0000, Percent Narrowed: 0.2897\n",
      "Epoch 126, Average Epoch Loss: 17985694.0000, Percent Narrowed: 0.2895\n",
      "Epoch 127, Average Epoch Loss: 17981418.0000, Percent Narrowed: 0.2895\n",
      "Epoch 128, Average Epoch Loss: 17964886.0000, Percent Narrowed: 0.2893\n",
      "Epoch 129, Average Epoch Loss: 17974454.0000, Percent Narrowed: 0.2894\n",
      "Epoch 130, Average Epoch Loss: 17979886.0000, Percent Narrowed: 0.2895\n",
      "Epoch 131, Average Epoch Loss: 17966088.0000, Percent Narrowed: 0.2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from models.BaselineEmbed import BaselineEmbed\n",
    "from models.LinearModel import LinearRegressionModel\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "token_len = 1\n",
    "embed_size = 1\n",
    "mapper = BaselineEmbed(dataset, token_len, embed_size)\n",
    "indexer = LinearRegressionModel(mapper.max_len * embed_size)\n",
    "\n",
    "model = LitIndexer(mapper, indexer)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('lightning_logs/')\n",
    "trainer = L.Trainer(accelerator=\"cpu\", logger=tb_logger)\n",
    "trainer.fit(model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
